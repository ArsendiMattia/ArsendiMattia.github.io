---
title: Quantifying uncertainty of football teams' number of shots using Stan.
date: 2023-01-12 
comments: true
toc: true
math: true
---

This tutorial aims to share a probabilistic approach for quantifying the uncertainty around the number of shots football teams make, given the matches' characteristics. 

### Plan

- [x] Introduce the data. 
- [x] Visualize some relevant aspects of the data.
- [x] Define the complete Bayesian Models. 
- [x] Quantitative predictive performance comparisons.

## Dataset
Let's dive directly into a snapshot of the analyzed dataset

| Team           | Opponent       | Shots          | Att_rating     | Def_rating     | Venue          | Time |
|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:----:|
| arsenal        | forest         | 15             | 82.56          | 73.33          | 1              | 1    |
| arsenal        | crystal        | 13             | 83.00          | 77.00          | 0              | 2    | 
| ...            | ...            | ...            | ...            | ...            | ...            | ...  | 
| berlin         | leverkusen     | 2              | 75.14          | 82.00          | 0              | 11   |
| berlin         | augsburg       | 14             | 75.43          | 73.75          | 1              | 12   |

Specifically, we have a collection of historical matches from the 2023/2024 season until 25/11/2023, considering the teams of the TOP 5 leagues in Europe (ENG, ITA, FRA, ESP, GER). For each match, the following features are gathered:

*Team*
: The team to which the focus is funneled, 

*Opponent*
: The club faced by the considered *Team*, 

*Shots*
: The number of shots made by the *Team*,

*Att_rating*
: Sum of the FIFA ratings (overall) of the considered *Team*'s players in the attack positions, based on the official lineup,

*Def_rating*
: Sum of the FIFA ratings (overall) of the  *Opponent*'s players in the defending positions, based on the official lineup,

*Venue*
: If 1, the match has been played in the *Team*'s home; otherwise the *Team* is playing away,

*Time*
: An index based on the chronological order with which the matches have been played with respect to a specific *Team*. 

> The dataset has been formed by combining [`FbRef`](https://fbref.com/en/) data (using the astonishing library [`worldfootballR`](https://jaseziv.github.io/worldfootballR/)) with the [`EA Sports FC`](https://www.kaggle.com/datasets/stefanoleone992/ea-sports-fc-24-complete-player-dataset?select=male_players.csv) dataset. 
{: .prompt-info }

At this stage, we do know very little about the dataset. However, the following hypotheses are legitim given the general domain of knowledge:

- Each team has its own mean and variance with respect to the number of shots, which can be drastically different among teams.
- We expect to observe more shots when the match is played in the *Team*'s home. 
- Higher is the difference between *Att_rating* and *Def_rating*, higher is the number of shots observed. 
- Matches that have been played closely with respect to the *Time* might be more correlated.

Here is the `/file-to-share/dataset-shots.csv`{: .filepath}.

## Data Viz

Let's find out if the data supports the formulated hypotheses.

### Mean(shots) distribution
We can see how the mean shots vary among the teams. Moreover, by segmenting by *Venue*, it can be noticed that the mean shots are higher when the match has been played in the *Team*'s home, as expected.
```R
df %>%
  group_by(Team, Venue) %>%
  summarise(
    shots_mean = mean(Shots)
  ) %>%
  ggplot(aes(x = shots_mean, fill = Venue)) +
  geom_density(alpha = 0.4, linewidth = 2) +
  theme_classic() +
  theme(text = element_text(size = 20), legend.key.size = unit(2, 'cm')) +
  scale_y_continuous(breaks = c(0, .1, .18)) +
  labs(x = "Mean(shots)")
```
![Desktop View](/posts/shots/first.png){: width="972" height="589"}


### Sd(shots) distribution
We can see how the *standard-deviation* of the shots varies among the teams. Moreover, the difference based on the *Venue* is lighter compared to what it has been observed in the mean shots distribution. 
```R
df %>%
  group_by(Team, Venue) %>%
  summarise(
    shots_sd = sd(Shots)
  ) %>%
  ggplot(aes(x = shots_sd, fill = Venue)) +
  geom_density(alpha = 0.4, linewidth = 2) +
  theme_classic() +
  theme(text = element_text(size = 20), legend.key.size = unit(2, 'cm')) +
  scale_y_continuous(breaks = c(0, .15, .25)) +
  labs(x = "Sd(shots)")
```
![Desktop View](/posts/shots/second.png){: width="972" height="589"}

### Mean(shots) vs Mean(Att_rating - Def_rating)
By taking the mean of the difference between *Att_rating* and *Def_rating* with respect to each team, a positive linear relationship with the mean shots is observable. Specifically, the intercept of the line among the matches played in the *Team*'s home seems to be higher. 
```r
df %>%
  group_by(Team, Venue) %>%
  summarise(
    shots_mean = mean(Shots),
    Att_Def_diff_mean = mean(Att_rating - Def_rating)
  ) %>%
  ggplot(aes(x = Att_Def_diff_mean, y = shots_mean, color = Venue)) +
  geom_point(size = 10) +
  theme_classic() +
  theme(text = element_text(size = 20), legend.key.size = unit(2, 'cm')) +
  labs(x = "Mean(Att_rating - Def_rating)", y = "Mean(shots)")
```
![Desktop View](/posts/shots/third.png){: width="972" height="589"}

## Complete Bayesian Models
In this context, since the number of shots is a positive number, a common practice is to model the logarithm scale-free value. Therefore, the following transformation is applied

$$ y = \log \left(\frac{\text{Shots}}{MAD(\text{Shots})}\right),$$

where the *MAD* represents the median absolute deviation function which is a robust estimation of the standard deviation.

### 1: Linear Regression
The following is the complete Bayesian model adopted in this first iteration

$$ y_n \sim \text{Normal}\left(f(x_n), \sigma\right),$$

where 

$$ f(x_n) = \alpha + \beta_1 \cdot \text{Att_Def_diff}_n + \beta_2 \cdot \text{Venue}_n,$$

$$ \alpha \sim \text{Normal}(0, .2),$$

$$ \beta_1 \sim \text{Normal}(.1, .5),$$

$$ \beta_2 \sim \text{Normal}(.1, .5),$$

$$ \log(\sigma) \sim \text{Normal}(0, .5).$$

The strategy adopted for selecting reasonable prior distributions has been:
1. retrivering the shots of the season 2022/2023,
2. computing the minimum, the maximum, and the quantile values 0.25, 0.5, and 0.75,
3. generating prior predictive distributions with most of the concentration in a specific acceptable interval, namely above the historical minimum, below the historical maximum, and with approximately the same historical quantiles.

This allows us to reach a reasonable compromise by avoiding using flat priors and obtaining a faster fitting with posterior distributions that are more informative and, hopefully, without divergences. The following is the Stan code for the Prior Predictive Chek performed
```stan
data {
  int<lower=1> N;
  vector[N] Att_Def_diff;
  vector[N] Venue;
}
transformed data {
  // Normalization
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;
}
generated quantities {
  real alpha = normal_rng(0, .2);
  real beta1 = normal_rng(.1, .5);
  real beta2 = normal_rng(.1, .5);
  real logsigma = normal_rng(0, .5);

  array[N] real y_gen;
  for(n in 1:N){
    y_gen[n] = normal_rng(
      alpha + beta1 * x1n[n] + beta2 * Venue[n],
      exp(logsigma)
    );
  }
}
```

The following is the Stan code used for drawing representative samples from the posterior distributions
```stan
data {
  int<lower=1> N;
  vector[N] Att_Def_diff;
  vector[N] Venue;
  vector[N] y;
}
transformed data {
  // Normalization
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  real ymean = mean(y);
  real ysd = sd(y);
  vector[N] yn = (y - ymean) / ysd;
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;
}
parameters {  
  real alpha;
  real beta1;
  real beta2;
  real logsigma;
}
model {
  alpha ~ normal(0, .2);
  beta1 ~ normal(.1, .5);
  beta2 ~ normal(.1, .5);
  logsigma ~ normal(0, .5);

  yn ~ normal(
    alpha + beta1 * x1n + beta2 * Venue,
    exp(logsigma)
  );
}
generated quantities {
  vector[N] log_lik;
  for (n in 1:N) log_lik[n] = normal_lpdf(
    yn[n] | alpha + beta1 * x1n[n] + beta2 * Venue[n], exp(logsigma)  
  );
}
```
The behaviors of the chains during the sampling satisfy all the standard requirements. Specifically, each parameter has a Split-$$\hat{R}$$ equal almost to 1 and an *ESS* larger than 5 times twice the number of the chains. Moreover, there are no divergent transitions.

### 2: Hierarchical Model (Intercept)
Given the assumption that the number of shots tends to look similar among matches belonging to the same team, the complete Bayesian model assumed in this second iteration is the following

$$ y_{nt} \sim \text{Normal}\left(f(x_{nt}), \sigma\right),$$

where 

$$ f(x_{nt}) = \alpha_t + \beta_1 \cdot \text{Att_Def_diff}_{nt} + \beta_2 \cdot \text{Venue}_{nt},$$

$$ \alpha_1, ..., \alpha_t, ... \alpha_T \sim \text{Normal}(\phi, \tau),$$

$$ \phi \sim \text{Normal}(0, .2),$$

$$ \tau \sim \text{HalfStudentT}(3, 0, .5),$$

$$ \beta_1 \sim \text{Normal}(.1, .5),$$

$$ \beta_2 \sim \text{Normal}(.1, .5),$$

$$ \log(\sigma) \sim \text{Normal}(0, .5),$$

where $t$ represents a specific *team* among a total of $T$ teams. In other words, we are assuming that each team has its own intercept value $\alpha_t$ which is drawn from a common population distribution. 

The strategy adopted for selecting reasonable prior distributions is the same as the one adopted in the first iteration, with the only difference being the following Stan code
```stan
data {
  int<lower=1> N;
  int<lower=1> N_teams;
  array[N] int teams_idx;
  vector[N] Att_Def_diff;
  vector[N] Venue;
}
transformed data {
  // Normalization
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;
}
generated quantities {
  real phi = normal_rng(0, .2);
  real<lower=0> tau = abs(student_t_rng(3, 0, .5));
  vector[N_teams] alpha_tilde = to_vector(normal_rng(
    rep_vector(0, N_teams), 
    rep_vector(1, N_teams)
  ));
  vector[N_teams] alpha = phi + tau * alpha_tilde;

  real beta1 = normal_rng(.1, .5);
  real beta2 = normal_rng(.1, .5);
  real logsigma = normal_rng(0, .5);

  array[N] real y_gen;
  for(n in 1:N){
    y_gen[n] = normal_rng(
      alpha[teams_idx[n]] + beta1 * x1n[n] + beta2 * Venue[n],
      exp(logsigma)
    );
  }
}
```

Representative samples from the posterior distributions are drawn using the Stan code below
```stan
data {
  int<lower=1> N;
  int<lower=1> N_teams;
  array[N] int teams_idx;
  vector[N] Att_Def_diff;
  vector[N] Venue;
  vector[N] y;
}
transformed data {
  // Normalization
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  real ymean = mean(y);
  real ysd = sd(y);
  vector[N] yn = (y - ymean) / ysd;
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;
}
parameters {  
  vector[N_teams] alpha_tilde;
  real phi;
  real<lower=0> tau;
  real beta1;
  real beta2;
  real logsigma;
}
transformed parameters {
  vector[N_teams] alpha;
  for (t in 1:N_teams) {
    alpha[t] = phi + tau * alpha_tilde[t];
  }
   
}
model {
  alpha_tilde ~ std_normal();
  phi ~ normal(0, .2);
  tau ~ student_t(3, 0, 0.5);
  beta1 ~ normal(.1, .5);
  beta2 ~ normal(.1, .5);
  logsigma ~ normal(0, .5);

  yn ~ normal(
    alpha[teams_idx] + beta1 * x1n + beta2 * Venue,
    exp(logsigma)
  );
}
generated quantities {
  vector[N] log_lik;
  for (n in 1:N) log_lik[n] = normal_lpdf(
    yn[n] | alpha[teams_idx[n]] + beta1 * x1n[n] + beta2 * Venue[n], exp(logsigma)  
  );
}
```

The behaviours of the chains satisfied the standard requirements without showing divergences. 

> The `non-centered parametrization` has been used for modeling $\alpha$.
{: .prompt-info }

### 3: Hierarchical Model (Variance)
The complete Bayesian model assumed in this third iteration is described as

$$ y_{nt} \sim \text{Normal}\left(f(x_{n}), \sigma_{t} \right),$$

where 

$$ f(x_{n}) = \alpha + \beta_1 \cdot \text{Att_Def_diff}_{n} + \beta_2 \cdot \text{Venue}_{n},$$

$$ \alpha \sim \text{Normal}(0, .2),$$

$$ \beta_1 \sim \text{Normal}(.1, .5),$$

$$ \beta_2 \sim \text{Normal}(.1, .5),$$

$$ \log(\sigma_1), ..., \log(\sigma_t), ... \log(\sigma_T) \sim \text{Normal}(\omega, \zeta),$$

$$ \omega \sim \text{Normal}(0, .5),$$

$$ \zeta \sim \text{HalfStudentT}(3, 0, .1).$$

In other words, we are assuming that each team $t$ has its own standard deviation value $\sigma_t$ which is drawn from a common population distribution. The prior predictive check has been performed using the below Stan code and same strategy mentioned above.  
```stan
data {
  int<lower=1> N;
  int<lower=1> N_teams;
  array[N] int teams_idx;
  vector[N] Att_Def_diff;
  vector[N] Venue;
}
transformed data {
  // Normalization
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;
}
generated quantities {

  real alpha = normal_rng(0, .2);
  real beta1 = normal_rng(.1, .5);
  real beta2 = normal_rng(.1, .5);
  
  real omega = normal_rng(0, .5);
  real<lower=0> zeta = abs(student_t_rng(3, 0, .1));
  vector[N_teams] logsigma_tilde = to_vector(normal_rng(
    rep_vector(0, N_teams), 
    rep_vector(1, N_teams)
  ));
  vector[N_teams] logsigma = omega + zeta * logsigma_tilde;


  array[N] real y_gen;
  for(n in 1:N){
    y_gen[n] = normal_rng(
      alpha + beta1 * x1n[n] + beta2 * Venue[n],
      exp(logsigma[teams_idx[n]])
    );
  }
}
```

The sampling has been performed by running
```stan
data {
  int<lower=1> N;
  int<lower=1> N_teams;
  array[N] int teams_idx;
  vector[N] Att_Def_diff;
  vector[N] Venue;
  vector[N] y;
}
transformed data {
  // Normalization
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  real ymean = mean(y);
  real ysd = sd(y);
  vector[N] yn = (y - ymean) / ysd;
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;
}
parameters {  
  real alpha;
  real beta1;
  real beta2;
  vector[N_teams] logsigma_tilde;
  real omega;
  real<lower=0> zeta;
}
transformed parameters {
  vector[N_teams] logsigma;
  for (t in 1:N_teams) {
    logsigma[t] = omega + zeta * logsigma_tilde[t];
  }
   
}
model {
  alpha ~ normal(0, .2);
  beta1 ~ normal(.1, .5);
  beta2 ~ normal(.1, .5);
  logsigma_tilde ~ std_normal();
  omega ~ normal(0, .5);
  zeta ~ student_t(3, 0, 0.1);

  yn ~ normal(
    alpha + beta1 * x1n + beta2 * Venue,
    exp(logsigma[teams_idx])
  );
}
generated quantities {
  vector[N] log_lik;
  for (n in 1:N) log_lik[n] = normal_lpdf(
    yn[n] | alpha + beta1 * x1n[n] + beta2 * Venue[n], exp(logsigma[teams_idx[n]])  
  );
}
```

The behaviours of the chains satisfied the standard requirements without showing divergences. 

> The `non-centered parametrization` has been used for modeling $\log(\sigma)$.
{: .prompt-info }

### 4: Hierarchical Gaussian Process
In this fourth iteration, a more complex solution is proposed: to model the possible correlation among the matches closed togheter with respect to the *Time* variable, a Gaussian Process (GP) is introduced. \\
Specifically, GP will be used to model the residual behaviour[^1] of the complete Bayesian model defined in the third iteration, by assuming a *Exponentiated quadratic kernel* (RBF) with respect to the *Time* variable. This will grant us the chance to model the *status* of a team which might vary thorught the season depending on external factors hard to measure. Moreover, the magnitude *s* and length scale *l* parameters of the RBF will be assumed to be different for each team[^2]. Therefore, the compelete Bayesian model assumed for this iteration is the following

$$ y_{nt} \sim \text{Normal}\left(f(x_{nt}), \sigma_{t} \right),$$

where 

$$ f(x_{nt}) = \alpha + \beta_1 \cdot \text{Att_Def_diff}_{n} + \beta_2 \cdot \text{Venue}_{n} + f_{nt},$$

$$ \alpha \sim \text{Normal}(0, .2),$$

$$ \beta_1 \sim \text{Normal}(.1, .5),$$

$$ \beta_2 \sim \text{Normal}(.1, .5),$$

$$ f_{1}, ..., f_{t}, ..., f_{T} \sim \text{GP}(0, K_{s_t,l_t}),$$

$$ \log(s_1), ..., \log(s_t), ..., \log(s_T)  \sim \text{Normal}(\exp(s_m), s_s),$$

$$ \log(l_1), ..., \log(l_t), ..., \log(l_T) \sim \text{Normal}(\exp(l_m), l_s),$$

$$ l_m \sim \text{InvGamma}(1, .5),$$

$$ l_s \sim \text{Normal}(0, .2),$$

$$ s_m \sim \text{Normal}(0, .5),$$

$$ s_s \sim \text{Normal}(0, .2),$$
  
$$ \log(\sigma_1), ..., \log(\sigma_t), ... \log(\sigma_T) \sim \text{Normal}(\omega, \zeta),$$

$$ \omega \sim \text{Normal}(0, .5),$$

$$ \zeta \sim \text{HalfStudentT}(3, 0, .1).$$

The prior predictive check has been performed using
``` stan
data {
  int<lower=1> N;
  int<lower=1> N_teams;
  array[N] int teams_idx;
  vector[N] Att_Def_diff;
  vector[N] Venue;
  
  int<lower=1> N_match_max;
  array[N] int Time;
}
transformed data {
  vector[N_match_max] time;
  for (i in 1:N_match_max) {
    time[i] = i;
  }

  // Normalization
  real tmean = mean(time);
  real tsd = sd(time);
  array[N_match_max] real tn = to_array_1d((time - tmean)/tsd);
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;

  // Numerical stability
  real sigma_intercept = 0.1;
  vector[N_match_max] jitter = rep_vector(1e-9, N_match_max);
}
generated quantities {
  real<lower=0> l_m = abs(inv_gamma_rng(1, .5));
  real<lower=0> l_s = abs(normal_rng(0, .2));
  real<lower=0> s_m = abs(normal_rng(0, .5));
  real<lower=0> s_s = abs(normal_rng(0, .2));

  vector[N_teams] l_tilde = to_vector(normal_rng(
    rep_vector(0, N_teams), 
    rep_vector(1, N_teams)
  ));
  vector[N_teams] s_tilde = to_vector(normal_rng(
    rep_vector(0, N_teams), 
    rep_vector(1, N_teams)
  ));

  vector<lower=0>[N_teams] s; 
  vector<lower=0>[N_teams] l; 
  array[N_teams] matrix[N_match_max, N_match_max] K;
  array[N_teams] matrix[N_match_max, N_match_max] L_K;
  matrix[N_teams, N_match_max] f;
  for (t in 1:N_teams) {
    l[t] = exp(log(l_m) + l_s * l_tilde[t]);
    s[t] = exp(log(s_m) + s_s * s_tilde[t]);
  
    K[t] =  gp_exp_quad_cov(tn, s[t], l[t]) + sigma_intercept^2;
    L_K[t] = cholesky_decompose(add_diag(K[t], jitter));

    vector[N_match_max] eta = to_vector(normal_rng(
      rep_vector(0, N_match_max), 
      rep_vector(1, N_match_max)
    ));

    f[t] = to_row_vector(L_K[t] * eta);
  }

  real omega = normal_rng(0, .5);
  real<lower=0> zeta = abs(student_t_rng(3, 0, 0.1));
  vector[N_teams] tau_tilde = to_vector(normal_rng(
    rep_vector(0, N_teams), 
    rep_vector(1, N_teams)
  ));
  vector[N_teams] tau = omega + zeta * tau_tilde;

  
  real alpha = normal_rng(0, .2);
  real beta1 = normal_rng(.1, .5);
  real beta2 = normal_rng(.1, .5); 

  array[N] real y_gen;
  for(n in 1:N){
    y_gen[n] = normal_rng(
      alpha + beta1 * x1n[n] + beta2 * Venue[n] + f[teams_idx[n], Time[n]],
      exp(tau[teams_idx[n]])
    );
  }
}
```

The Stan code to sample from the posterior distributions
``` stan
data {
  int<lower=1> N;
  int<lower=1> N_teams;
  array[N] int teams_idx;
  vector[N] Att_Def_diff;
  vector[N] Venue;
  vector[N] y;
  
  int<lower=1> N_match_max;
  array[N] int Time;
}
transformed data {
  vector[N_match_max] time;
  for (i in 1:N_match_max) {
    time[i] = i;
  }

  // Normalization
  real tmean = mean(time);
  real tsd = sd(time);
  array[N_match_max] real tn = to_array_1d((time - tmean)/tsd);
  real x1mean = mean(Att_Def_diff);
  real x1sd = sd(Att_Def_diff);
  real ymean = mean(y);
  real ysd = sd(y);
  vector[N] yn = (y - ymean) / ysd;
  vector[N] x1n = (Att_Def_diff - x1mean) / x1sd;

  // Numerical stability
  real sigma_intercept = 0.1;
  vector[N_match_max] jitter = rep_vector(1e-9, N_match_max);
}
parameters {
  // Population-level parameters
  real<lower=0> l_m;   
  real<lower=0> l_s;   
  real<lower=0> s_m; 
  real<lower=0> s_s; 
  
  // Per-team parameters (non-centered parameterization)
  vector[N_teams] l_tilde;   
  vector[N_teams] s_tilde; 
  
  // GP non-centered parametrization
  vector[N_teams * N_match_max] eta;
  
  real alpha;
  real beta1;
  real beta2;
  real omega;
  real<lower=0> zeta;
  vector[N_teams] logsigma_tilde;
}
transformed parameters {
  // Per-team parameters
  vector<lower=0>[N_teams] s; //signal standard deviation
  vector<lower=0>[N_teams] l; //length scale
  row_vector[N_teams] logsigma;
  
  // Per-team Covariance matrix 
  array[N_teams] matrix[N_match_max, N_match_max] K;
  array[N_teams] matrix[N_match_max, N_match_max] L_K;
  matrix[N_teams, N_match_max] f;
  matrix[N_teams, N_match_max] eta_matrix = to_matrix(eta, N_teams, N_match_max);
  for (t in 1:N_teams) {
    // Non-centered parameterization of per-team parameters
    l[t] = exp(log(l_m) + l_s * l_tilde[t]);
    s[t] = exp(log(s_m) + s_s * s_tilde[t]);
    logsigma[t] = omega + zeta * logsigma_tilde[t];

    K[t] = gp_exp_quad_cov(tn, s[t], l[t]) + sigma_intercept^2;
    L_K[t] = cholesky_decompose(add_diag(K[t], jitter));

    // Non-centered parametrization of per-team GP 
    f[t] = to_row_vector(
      L_K[t] * to_vector(eta_matrix[t])
    ); 
  }
}
model {
  // Priors (on population-level params)
  l_m ~ inv_gamma(1, .5);
  l_s ~ normal(0, .2);
  s_m ~ normal(0, .5);
  s_s ~ normal(0, .2);

  l_tilde ~ std_normal(); //log(l) ~ normal(exp(l_m), l_s)
  s_tilde ~ std_normal();  //log(s) ~ normal(exp(s_m), s_s)
  logsigma_tilde ~ std_normal(); //logsigma ~ normal(omega, zeta);
  
  // Non-centered parametrization GP
  eta ~ std_normal();

  omega ~ normal(0, .5);
  zeta ~ student_t(3, 0, 0.1);
  alpha ~ normal(0, .2);
  beta1 ~ normal(.1, .5);
  beta2 ~ normal(.1, .5);
  
  for (n in 1:N) {
    yn[n] ~ normal(
      alpha + beta1 * x1n[n] + beta2 * Venue[n] + f[teams_idx[n], Time[n]], 
      exp(logsigma[teams_idx[n]]) 
    );
  }
}
generated quantities {
  vector[N] log_lik;
  for (n in 1:N) log_lik[n] = normal_lpdf(
    yn[n] |alpha + beta1 * x1n[n] + beta2 * Venue[n] + f[teams_idx[n], Time[n]], exp(logsigma[teams_idx[n]])  
  );
}
```

> The `non-centered parametrization` has been used for modeling $\log(s)$, $\log(l)$ and for sampling from the GP.
{: .prompt-info }

To improve the warmup and avoiding that the chains get stuck, the sampling for this iteration has been performed by initialing the NUTS algorithms using the output of Pathfinder[^3] using short paths, as suggested from [Aki Vehtari's case study](https://users.aalto.fi/~ave/casestudies/Birthdays/birthdays.html#Model_1:_Slow_trend). By doing so, the behaviours of the chains satisfied the standard requirements without showing divergences. 

## Predictive performances
The comparison among the predictive performances of the models assumed in the iterations has been performed using LOO-CV [^4], which gives the following result

| Iteration      | elpd_diff      | se_diff        |
|:--------------:|:--------------:|:--------------:|
| Model 4        | 0.0            | 0.0            |
| Model 3        | -5.2           | 2.9            |
| Model 2        | -8.4           | 6.6            |
| Model 1        | -12.3          | 7.2            |


## Reverse Footnote

[^1]: Betancourt, Michael (2020). Robust Gaussian Process Modeling. Retrieved from https://github.com/betanalpha/knitr_case_studies/tree/master/gaussian_processes, commit e10083abbcdb65c745f840ab9d2da58229fa9af3. 
[^2]: Hasz, Brendan (2018). Multilevel Gaussian Processes and Hidden Markov Models with Stan. Retrieved from https://brendanhasz.github.io/2018/11/15/hmm-vs-gp-part2.html
[^3]: Zhang, L., Carpenter, B., Gelman, A. and Vehtari, A. (2022) ‘Pathfinder: Parallel quasi-newton variational inference’, Journal of Machine Learning Research, 23(306).
[^4]: Vehtari, A., Gelman, A. and Gabry, J. (2017) ‘Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC’, Statistics and Computing, 27, pp. 1413–1432.
